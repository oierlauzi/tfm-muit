\documentclass[../main.tex]{subfiles}

\begin{document}
We have observed that our implementation offers exceptional performance in low resolution alignments but struggles to offer superior results for higher resolutions. We would like to focus our future work enhancing the alignment algorithm so that it can offer matchless performance both for low and high resolutions. To do so, we have a couple of ideas that could help to improve the effectiveness at high resolution. Many of the ideas have been already implemented, but still require extensive testing to be conclusive on their results. Additionally, other use cases within the \gls{cryoem} context should be explored.

\section{Weighted distances}
The alignment algorithms offers the possibility to compute distances based on some weighting scheme. Other refinement algorithms such as Relion and Cryosparc use a \gls{mle} approach which weights each Fourier coefficient with the inverse of the measured noise power ($\sigma^{-2}$) for that frequency component.

Even though the weighting is already implemented in the alignment algorithm, we have not been able to determine a proper weighting scheme which improves on the results. Aside from the previously mentioned ($\sigma_N^{-2}$) approach, we have also tried using the \gls{snr} as a weight source (which also uses the $\sigma_N^{2}$ term in the denominator). The main issue related to them is that we are not able to obtain a reliable estimation of the noise \gls{ssnr}. Thus, there is some work to be done regarding the determination of the noise model of the dataset and testing the alignment algorithm using weights deduced from this noise model.

\section{Replacement of the Wiener filter for high resolution}
In Chapter \ref{chap:results} we empirically demonstrated that Wiener deconvolution of the \gls{ctf} is an effective way to tackle the \gls{ctf} when aligning particles. However, those tests were conducted at low resolution ($15 \si{\angstrom}$). Indeed, the \gls{ctf} has increasingly more zeros in high frequency. These zeros induce a systematic error on the distance metric, suggesting that this may be one of the causes of problems for high resolution alignments.

Nevertheless, the alignment program offers the possibility of applying the \gls{ctf} to the reference gallery (instead of correcting it on the experimental images). Although some tests were carried out at high resolution using this alternative approach, the results were not conclusive. Hence, further testing is required to establish a proper approach for tackling the \gls{ctf} with high resolution alignments. Moreover, this should be done once a reliable weighting scheme has been deduced.

\section{Local searches}
The vector compression techniques described in Chapter \ref{chap:implementation} can realiably compress a dataset of a couple of million of vectors. In spite of this, the reference dataset size grows rapidly as the resolution increases. Thus, for high resolution alignments the vector quantisation techniques impose a restriction. A possible solution to this issue is to reduce the reference dataset size by performing local alignments.

Assuming that prior information about the alignment of the experimental particles is known, we can reduce our search space to a reduced range around the prior alignment parameters. A first approach to do so would involve only generating in-plane transformations of the reference images in a limited range. Then, each experimental image would be oriented and centred according to its prior alignment information. 

Nevertheless, local alignments need to be taken with care. As its name suggests, it searches for local minimas, not global ones. Hence, if the prior information is in a ``valley'' that leads to a local minima, then the algorithm will not be able to find the global minima. A practical example of this issue would be the EMPIAR-10256 dataset explored in Chapter \ref{chap:results}. We observed that at low resolution we are not able to distinguish among the pseudo-symmetrical views of the protein. Hence, if this information were provided as the starting point for a local alignment, this algorithm would not be able to ``escape'' those incorrectly assigned pseudo-symmetrical views.

\section{Applications of the image alignment algorithm}
The importance of the image alignment in \gls{cryoem} image processing has been a lemma in this document. Indeed, image alignment is used in many steps of a typical \gls{spa} workflow, such as the 2D classification, ab-initio volume reconstruction, 3D refinement and 3D classification. In this work we have employed the later two use cases as a playground for our tests. Once alignment algorithm has been perfected, we would like expand its applications to other domains. 

Current ab-initio algorithms work by frequently aligning and reconstructing with small batches of the dataset. This means that the reference gallery changes very often, making our alignment algorithm less suitable for this application.

However, the 2D classification problem is a perfect target for our alignment algorithm. These algorithms are very similar to the 3D refinement but instead of using projections of the current volume as the reference gallery, it uses particle averages. Then all the experimental particles are aligned to these averages, and used for updating them.

Another promising use case of this alignment algoritm is \gls{sta}. This would diversify the applications of the algorithm towards the emerging field of \gls{cryoet}. In essence, \gls{cryoet} is very similar to \gls{cryoem}, but instead of acquiring each spot of the sample grid one, it is acquired reputedly with a varying tilt angle. This has the advantage that it allows directly reconstructing a volume without guessing the angles (as the tilt angles are known). However, the exposure of each tilt angle is considerably low, so the \gls{snr} of the images is worse. Additionally, not all possible tilt angles are acquired, producing a missing wedge in Fourier space.

To solve these issues, the \gls{sta} technique is used, where repetitions of a given structure in the tomogram are aligned and averaged to enhance \gls{snr} and resolution. In essence, this problem can be seen as the analogy of the 2D classification for 3 dimensional images (volumes).

The \gls{sta} problem can be approached from a 3D particle alignment point of view. The 3D alignment is a problem that we have solved for performing 3D refinements. As described earlier, the 3D alignment consists in projecting the current volume from all possible directions to form a reference gallery. Then each experimental image is searched across all the images of this gallery to find a best match. In the case of \gls{sta}, we would use the projections of each subtomogram (that do not involve the missing wedge) for this alignment. Once all the projections have been angular assigned, we could combine their 3D alignment information alongside the projection restrictions to obtain the alignment of the subtomogram itself.

\end{document}